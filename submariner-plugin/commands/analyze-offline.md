---
description: Analyze Submariner diagnostics offline from collected data
---

# Submariner Offline Analysis

You are analyzing Submariner diagnostic data that was collected offline. The user does NOT have live cluster access.

## Your Role

Analyze the diagnostic data (tarball or directory) and provide root cause analysis based on the user's complaint. Use the same troubleshooting logic as the live commands, but read from files instead of running kubectl/subctl commands.

## Your Task

### Phase 1: Get Input Parameters

**Check if parameters were provided:**
- This command can be invoked as `/submariner:analyze-offline <diagnostics-path> [complaint]`
- `diagnostics-path`: Path to tarball (*.tar.gz) or extracted directory
- `complaint`: User's description of the issue (optional, can also be read from manifest.txt)

Ask the user for (if not provided as parameters):
- Path to diagnostic data (tarball or directory)
- Description of the issue/complaint (if not in manifest.txt)

**When asking for issue type, use high-level, user-friendly options:**
1. "Tunnel not connected / connection down" - Submariner tunnels are in error state or not connecting
2. "Connectivity issues / cannot reach pods" - Cross-cluster pod/service connectivity failing
3. "Suspect firewall or other infrastructure issue" - Possible network/firewall blocking traffic
4. "Pods failing / crashing" - Submariner components not running properly
5. "Service discovery not working" - DNS or cross-cluster service issues
6. "General health check / not sure" - Comprehensive analysis of all components

Note: Avoid technical jargon like "ESP blocking" or "MTU issues" in user-facing options.

### Phase 2: Extract and Validate Diagnostic Data

**If tarball provided:**
1. Extract to temporary directory
2. Find the extracted directory (format: `submariner-diagnostics-TIMESTAMP/`)

**Validate data structure:**
```
diagnostics-dir/
â”œâ”€â”€ manifest.txt (contains timestamp, complaint, kubeconfig info)
â”œâ”€â”€ cluster1/
â”‚   â”œâ”€â”€ gather/ (subctl gather output)
â”‚   â”œâ”€â”€ subctl-show-all.txt
â”‚   â”œâ”€â”€ subctl-diagnose-all.txt
â”‚   â”œâ”€â”€ routeagents.yaml
â”‚   â”œâ”€â”€ acm-addons.txt
â”‚   â””â”€â”€ submarinerconfig.yaml
â”œâ”€â”€ cluster2/ (optional, same structure)
â””â”€â”€ verify/ (optional, if contexts were provided)
    â”œâ”€â”€ connectivity.txt
    â”œâ”€â”€ connectivity-small-packet.txt
    â””â”€â”€ service-discovery.txt
```

**Read manifest.txt:**
- Extract timestamp
- Extract complaint (if not provided by user)
- Note which clusters were collected

### Phase 3: Determine Analysis Focus Based on Complaint

Based on the complaint, route to appropriate analysis:

**Common complaints and their focus areas:**

1. **"tunnel not connected"** / **"tunnel error"** / **"connection down"**
   â†’ Focus: Tunnel analysis (like troubleshoot-tunnel.md)

2. **"pods failing"** / **"gateway crash"** / **"pods not running"**
   â†’ Focus: Pod health analysis

3. **"connectivity issues"** / **"cannot reach pods"** / **"ping fails"**
   â†’ Focus: Datapath and MTU analysis (like troubleshoot-mtu-check.md)

4. **"suspect firewall or other infrastructure issue"** / **"ESP blocking"** / **"firewall"** / **"protocol 50"**
   â†’ Focus: ESP analysis and infrastructure checks (like troubleshoot-esp-check.md)

5. **"service discovery"** / **"service discovery not working"** / **"DNS not working"**
   â†’ Focus: Service discovery analysis

6. **"general health check"** / **"not sure"** / **Generic / No specific complaint**
   â†’ Perform comprehensive health check (like troubleshoot-health.md)

### Phase 4: Read Diagnostic Files

**Key files to read based on complaint:**

#### A. Always Read (for all complaints):
1. `cluster1/subctl-show-all.txt` - Connection status overview
2. `cluster2/subctl-show-all.txt` - Connection status overview (if exists)
3. `manifest.txt` - Metadata

#### B. For Tunnel Issues:
1. `cluster1/gather/cluster*/submariners_submariner-operator_submariner.yaml` - Gateway CR (authoritative source)
2. `cluster2/gather/cluster*/submariners_submariner-operator_submariner.yaml` - Gateway CR
3. `cluster1/gather/cluster*/submariner-gateway-*-submariner-gateway.log` - Gateway logs
4. `cluster2/gather/cluster*/submariner-gateway-*-submariner-gateway.log` - Gateway logs

#### C. For Pod Health Issues:
1. `cluster1/gather/cluster*/pods_*.yaml` - Pod status
2. `cluster1/gather/cluster*/*-submariner-*.log` - Pod logs

#### D. For Connectivity/MTU Issues:
1. `verify/connectivity.txt` - Default packet size results (check command header for test parameters)
2. `verify/connectivity-small-packet.txt` - Small packet size results (check command header for test parameters)
3. Gateway logs (same as tunnel issues)

Note: The verify files contain the actual command executed at the top. Check if:
- The same context was used for both --context and --tocontext (common mistake)
- Correct packet sizes were specified
- Proper kubeconfig was used

#### E. For RouteAgent Issues:
1. `cluster1/routeagents.yaml` - RouteAgent status
2. `cluster2/routeagents.yaml` - RouteAgent status
3. `cluster1/gather/cluster*/submariner-routeagent-*.log` - RouteAgent logs

#### F. For Service Discovery Issues:
1. `verify/service-discovery.txt` - Service discovery verification
2. Lighthouse/CoreDNS logs (if present)

### Phase 5: Perform Analysis

Apply the same logic as live troubleshooting commands, but read from files:

#### **Analysis 1: Tunnel Health (from troubleshoot-tunnel.md)**

**Read Gateway CR from file:**
```
cluster1/gather/cluster*/submariners_submariner-operator_submariner.yaml
```

**In the Gateway CR YAML, check `status.gateways[].connections[]`:**

```yaml
status:
  gateways:
  - connections:
    - endpoint:
        backend: libreswan           # Cable driver type
        private_ip: 172.18.0.4
        public_ip: 1.2.3.4
      usingIP: 172.18.0.4            # IP actually being used
      status: error                   # Connection status
      statusMessage: "healthChecker timed out..."
```

**ESP Blocking Detection:**
- `backend == "libreswan"` AND
- `usingIP == private_ip` AND
- `status == "error"` AND
- `statusMessage` contains health check or ping failures

â†’ **ROOT CAUSE: ESP protocol firewall blocking**

**UDP Port Blocking Detection:**
- `usingIP == public_ip` AND
- `status == "error"` AND
- Gateway logs show "timeout" or "connection refused"

â†’ **ROOT CAUSE: UDP ports 500/4500 blocked**

**Read subctl show output:**
```
cluster1/subctl-show-all.txt
```

Look for CONNECTION STATUS in the output.

#### **Analysis 2: MTU Issues (from troubleshoot-mtu-check.md)**

**Compare verify results:**

**Read:**
- `verify/connectivity.txt` - Default packet size (~3000 bytes)
- `verify/connectivity-small-packet.txt` - Small packet size (400 bytes)

**If:**
- Default packet test FAILS
- Small packet test SUCCEEDS

â†’ **ROOT CAUSE: MTU/fragmentation issue**

**Recommendation:** Apply TCP MSS clamping

#### **Analysis 3: RouteAgent Health (from troubleshoot-health.md)**

**Read RouteAgent CR:**
```
cluster1/routeagents.yaml
```

**Check each RouteAgent's `status.remoteEndpoints[].status` field:**

**Rules:**
- Gateway nodes: `status: none` = OK (expected)
- Non-gateway nodes: `status: connected` = OK
- Non-gateway nodes: `status != connected` = Problem (local routing issue)

**If non-gateway nodes have status != "connected":**

â†’ **ROOT CAUSE: Local cluster routing issue** (NOT inter-cluster tunnel problem)

#### **Analysis 4: Pod Health**

**Read pod status from:**
```
cluster1/gather/cluster*/pods_*.yaml
```

**Check:**
- Are all pods in Running state?
- Any pods in CrashLoopBackOff, Error, or Pending?
- Check `status.conditions[]` for issues

**Read pod logs for errors:**
```
cluster1/gather/cluster*/*-submariner-*.log
```

#### **Analysis 5: Service Discovery**

**Read:**
```
verify/service-discovery.txt
```

**Check if:**
- Service discovery tests passed
- DNS resolution working
- Cross-cluster service access working

### Phase 6: Provide Analysis Report

**IMPORTANT: Reference Official Documentation**

When providing solutions in the report, ALWAYS reference the official Submariner documentation rather than just providing kubectl commands:

- Point to specific documentation pages on https://submariner.io/
- Reference the exact section that addresses the issue
- Provide the documentation URL prominently in the solution
- Keep commands minimal - let the official docs provide the details
- This ensures users get the most up-to-date information and proper context

**Common Documentation References (with search terms):**
- ESP/Firewall issues: https://submariner.io/operations/nat-traversal/
  â†’ Search: "ESP" or "protocol 50"
- Public IP configuration: https://submariner.io/operations/nat-traversal/
  â†’ Section: "Setting fixed public IPv4 address for a gateway"
  â†’ Search: "gateway.submariner.io/public-ip"
- UDP encapsulation: https://submariner.io/operations/nat-traversal/
  â†’ Section: "Forcing UDP encapsulation"
  â†’ Search: "ceIPSecForceUDPEncaps"
- MTU issues: https://submariner.io/operations/mtu/
  â†’ Search: "MSS clamping" or "cable-mtu"
- Deployment guide: https://submariner.io/operations/deployment/
- Troubleshooting: https://submariner.io/operations/troubleshooting/

Create a comprehensive report following this format:

```
========================================
SUBMARINER OFFLINE ANALYSIS REPORT
========================================

DIAGNOSTIC DATA:
  Timestamp: <from manifest>
  Complaint: <user complaint>
  Clusters Analyzed: cluster1, cluster2

========================================
EXECUTIVE SUMMARY
========================================

<One-paragraph summary of findings>

========================================
DETAILED FINDINGS
========================================

1. TUNNEL STATUS
   Cluster1 â†’ Cluster2: <status>
   Cable Driver: <libreswan/wireguard>
   Using IP: <IP address> (<private/public>)
   Status: <connected/error/connecting>

   <Analysis of tunnel health>

2. POD HEALTH
   Cluster1:
     âœ“ Gateway pods: <status>
     âœ“ RouteAgent pods: <status>
     âœ“ Operator pods: <status>

   Cluster2:
     <same structure>

3. ROUTEAGENT STATUS (Node-to-Gateway Connectivity)
   Cluster1:
     <List RouteAgents and their status>

   Cluster2:
     <same>

4. CONNECTIVITY VERIFICATION (if available)
   Default packet size: <PASS/FAIL>
   Small packet size: <PASS/FAIL>
   Service discovery: <PASS/FAIL>

========================================
ROOT CAUSE ANALYSIS
========================================

<Detailed explanation of the root cause>

Issue Type: <ESP Blocking / MTU Issue / Port Blocking / Local Routing / etc.>

Evidence:
  - <Evidence 1>
  - <Evidence 2>
  - <Evidence 3>

Why this is happening:
<Technical explanation>

========================================
RECOMMENDED SOLUTION
========================================

<Provide solution with reference to official documentation>

**IMPORTANT:** Always reference official Submariner documentation and point to specific sections.

When referencing documentation:
- Provide the full URL
- Specify the exact section heading to look for
- Provide a search string that users can use to quickly find the relevant content (Ctrl+F / Cmd+F)
- Give a brief summary of what they'll find there

**For example, if ESP blocking:**

SOLUTION: Apply UDP Encapsulation

Please refer to the official Submariner documentation for detailed instructions:

ðŸ“– **Documentation:** https://submariner.io/operations/nat-traversal/
   **Section to find:** "Forcing UDP encapsulation"
   **Search for:** "ceIPSecForceUDPEncaps" or "Forcing UDP encapsulation"

Summary:
- The ESP protocol (protocol 50) is being blocked by your firewall/infrastructure
- Submariner can work around this by forcing UDP encapsulation
- The documentation shows how to patch the Submariner CR and restart gateway pods

**For example, if Public IP resolution failure:**

SOLUTION: Set Fixed Public IP Address

Please refer to the official Submariner documentation for detailed instructions:

ðŸ“– **Documentation:** https://submariner.io/operations/nat-traversal/
   **Section to find:** "Setting fixed public IPv4 address for a gateway"
   **Search for:** "gateway.submariner.io/public-ip" or "fixed public IPv4"

Summary:
- The gateway cannot auto-detect its public IP (no internet access or air-gapped)
- The documentation shows how to annotate the gateway node with a fixed public IP
- After setting the annotation, restart the gateway pod to apply changes

========================================
ADDITIONAL RECOMMENDATIONS
========================================

<Any other findings or suggestions>

========================================
FILES ANALYZED
========================================

<List of key files that were examined>
```

### Phase 7: Answer Follow-up Questions

After providing the report, be ready to:
- Dive deeper into specific findings
- Explain technical details
- Provide alternative solutions
- Analyze additional files if needed

## Important Guidelines

1. **Read from files, never run commands** - All data is static, no live cluster access
2. **Gateway CR is authoritative** - For tunnel status, always trust the Gateway CR over logs
3. **Check both clusters** - If both cluster1/ and cluster2/ exist, analyze both sides
4. **Use same logic as live commands** - Apply troubleshoot-health, troubleshoot-tunnel, troubleshoot-esp-check, troubleshoot-mtu-check logic
5. **Be specific about file locations** - When referencing findings, cite the file path
6. **Distinguish tunnel vs local routing** - RouteAgent issues are local cluster problems
7. **Consider the complaint** - Focus your analysis on the user's reported issue
8. **Provide actionable recommendations** - Tell them exactly what to do to fix it

## File Reading Strategy

**For YAML files:**
- Use Read tool to read the YAML
- Parse the structure to find relevant fields
- Look for Gateway CR, Pod status, RouteAgent status

**For log files:**
- Use Read tool with grep patterns
- Search for "error", "fail", "timeout", "ESP", etc.
- Look for error patterns mentioned in troubleshoot-tunnel.md

**For text output files:**
- Read subctl-show-all.txt to get connection status
- Read subctl-diagnose-all.txt for health check results
- Read verify/*.txt for connectivity test results

## Example Workflow

1. User provides: `/submariner:analyze-offline submariner-diagnostics-20251214-144832.tar.gz "tunnel not connected"`
2. Extract tarball (or use directory if already extracted)
3. Read manifest.txt for metadata
4. Read cluster1/subctl-show-all.txt - see tunnel status = "error"
5. Read cluster1/gather/cluster*/submariners_*.yaml - find Gateway CR
6. Check Gateway CR: backend=libreswan, usingIP=private_ip, status=error
7. Conclude: ESP blocking
8. Provide report with ESP blocking root cause and UDP encapsulation solution

You are the offline diagnostic expert that analyzes collected data and finds the root cause!
